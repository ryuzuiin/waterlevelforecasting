{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOQTXSB41c6ztksiL4jwSq2",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ryuzuiin/waterlevelforecasting/blob/main/%E6%99%82%E7%B3%BB%E5%88%97%E5%88%86%E6%9E%90.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from statsmodels.tsa.stattools import adfuller, kpss, acf\n",
        "from statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n",
        "from statsmodels.stats.diagnostic import acorr_ljungbox\n",
        "\n",
        "from scipy.stats import shapiro, kstest, norm"
      ],
      "metadata": {
        "id": "cmqLx4X0a-zS"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "class TimeSeriesAnalyzer:\n",
        "    def __init__(self, data, date_column, value_column, freq='10T'):\n",
        "        self.data = data\n",
        "        self.date_column = date_column\n",
        "        self.value_column = value_column\n",
        "        self.freq = freq\n",
        "        self.processed_data = None\n",
        "\n",
        "    def is_datetime_column(self):\n",
        "        '''\n",
        "        detect the datetime column\n",
        "        '''\n",
        "        if self.date_column in self.data.columns:\n",
        "            return pd.api.types.is_datetime64_any_dtype(self.data[self.date_column])\n",
        "        else:\n",
        "            raise ValueError(f'Column {self.date_column} is not found in data')\n",
        "\n",
        "    def make_datetime(self):\n",
        "        '''\n",
        "        if not datetime type, convert to datetime type.\n",
        "        input: data[date_column]\n",
        "        output: data[date_column]\n",
        "        '''\n",
        "        if not self.is_datetime_column():\n",
        "            self.data[self.date_column] = pd.to_datetime(self.data[self.date_column])\n",
        "        return self.data[self.date_column]\n",
        "\n",
        "    def is_time_ordered(self):\n",
        "        '''\n",
        "        detect the time order\n",
        "        input: data[date_column]\n",
        "        output: bool\n",
        "        '''\n",
        "        if self.is_datetime_column():\n",
        "            return self.data[self.date_column].is_monotonic_increasing\n",
        "        else:\n",
        "            return self.make_datetime().is_monotonic_increasing\n",
        "\n",
        "    def set_date_index(self):\n",
        "        if not self.is_time_ordered():\n",
        "            self.data.sort_values(by=self.date_column, inplace=True)\n",
        "        self.data.set_index(self.date_column, inplace=True)\n",
        "        return self.data\n",
        "\n",
        "    def check_missing_values(self, fill_method=None):\n",
        "        '''\n",
        "        detect the missing value and handle them\n",
        "        input: fill_method\n",
        "        output: boolean value\n",
        "        '''\n",
        "        missing_values = self.processed_data[self.value_column].isnull().sum()\n",
        "\n",
        "        if missing_values > 0:\n",
        "            print(f'{missing_values} missing data found')\n",
        "\n",
        "            if fill_method == 'ffill':\n",
        "                self.processed_data[self.value_column].fillna(method='ffill', inplace=True)\n",
        "            elif fill_method == 'bfill':\n",
        "                self.processed_data[self.value_column].fillna(method='bfill', inplace=True)\n",
        "            elif fill_method == 'mean':\n",
        "                self.fill_with_mean_of_neighbor()\n",
        "            elif fill_method == 'drop':\n",
        "                self.processed_data.dropna(subset=[self.value_column], inplace=True)\n",
        "            elif fill_method == 'linear':\n",
        "                self.processed_data[self.value_column].interpolate(method='linear', inplace=True)\n",
        "            elif fill_method == 'time':\n",
        "                self.processed_data[self.value_column].interpolate(method='time', inplace=True)\n",
        "\n",
        "            return True\n",
        "        else:\n",
        "            print('No missing data found')\n",
        "            return False\n",
        "\n",
        "    def fill_with_mean_of_neighbor(self):\n",
        "        '''\n",
        "        fill the missing value with mean of neighbor\n",
        "        '''\n",
        "        for i in range(1, len(self.processed_data) - 1):\n",
        "            if pd.isnull(self.processed_data.iloc[i][self.value_column]):\n",
        "                prev_value = self.processed_data.iloc[i-1][self.value_column]\n",
        "                next_value = self.processed_data.iloc[i+1][self.value_column]\n",
        "                if pd.notnull(prev_value) and pd.notnull(next_value):\n",
        "                    self.processed_data.iloc[i][self.value_column] = (prev_value + next_value) / 2\n",
        "\n",
        "    def is_full_range_time_series(self):\n",
        "        '''\n",
        "        check the full range time series and construct a full range time series\n",
        "        '''\n",
        "        if not isinstance(self.data.index, pd.DatetimeIndex):\n",
        "            self.set_date_index()\n",
        "\n",
        "        full_range = pd.date_range(start=self.data.index.min(), end=self.data.index.max(), freq=self.freq)\n",
        "        is_full_range = self.data.index.equals(full_range)\n",
        "\n",
        "        if is_full_range:\n",
        "            print('The time series is a full range time series')\n",
        "            self.processed_data = self.data.copy()\n",
        "        else:\n",
        "            print('The time series is not a full range time series')\n",
        "            self.processed_data = self.data.reindex(full_range)\n",
        "            self.check_missing_values(fill_method='linear')\n",
        "            self.processed_data.sort_index(inplace=True)\n",
        "\n",
        "        return self.processed_data\n",
        "\n",
        "    def drop_minute_value(self, minutes_to_drop=[15, 45]):\n",
        "        '''\n",
        "        drop the unnecessary minute value\n",
        "        '''\n",
        "        if not isinstance(self.processed_data.index, pd.DatetimeIndex):\n",
        "            self.set_date_index()\n",
        "\n",
        "        self.processed_data = self.processed_data[~self.processed_data.index.minute.isin(minutes_to_drop)]\n",
        "        return self.processed_data\n",
        "\n",
        "    def is_stationary(self, significance_level=0.05):\n",
        "        '''\n",
        "        ADF test\n",
        "        '''\n",
        "        result = adfuller(self.processed_data[self.value_column])\n",
        "        print('====================================================')\n",
        "        print('ADF Statistic: %f' % result[0])\n",
        "        print('p-value: %f' % result[1])\n",
        "        print('====================================================')\n",
        "        return result[1] <= significance_level\n",
        "\n",
        "    def is_trend_stationary(self, significance_level=0.05):\n",
        "        '''\n",
        "        KPSS test(trend stationary)\n",
        "        '''\n",
        "        result = kpss(self.processed_data[self.value_column], regression='ct')\n",
        "        print('====================================================')\n",
        "        print('KPSS Statistic: %f' % result[0])\n",
        "        print('p-value: %f' % result[1])\n",
        "        print('====================================================')\n",
        "        return result[1] > significance_level\n",
        "\n",
        "    def is_necessary_differencing(self):\n",
        "        '''\n",
        "        check the stationarity of the time series and make a decision of whether to perform differencing\n",
        "        '''\n",
        "        adf_stationary = self.is_stationary()\n",
        "        kpss_stationary = self.is_trend_stationary()\n",
        "\n",
        "        # Situation 1: both ADF and KPSS consider the time series is stationary\n",
        "        if adf_stationary and kpss_stationary:\n",
        "            print('The time series is already stationary')\n",
        "            return False\n",
        "\n",
        "        # Situation 2: ADF found unit root, but KPSS found the time series is trend stationary\n",
        "        elif not adf_stationary and kpss_stationary:\n",
        "            print('The time series is trend stationary')\n",
        "            return True\n",
        "\n",
        "        # Situation 3: ADF found no unit root, but KPSS found the time series is not trend stationary\n",
        "        elif adf_stationary and not kpss_stationary:\n",
        "            print('The time series is not trend stationary')\n",
        "            return True\n",
        "\n",
        "        # Situation 4: ADF and KPSS both consider the time series non-stationary\n",
        "        elif not adf_stationary and not kpss_stationary:\n",
        "            print('The time series is not stationary')\n",
        "            return True\n",
        "\n",
        "    def make_stationarity(self, differencing_order=1):\n",
        "        '''\n",
        "        make the time series stationary\n",
        "        '''\n",
        "        if self.is_necessary_differencing():\n",
        "            for i in range(differencing_order):\n",
        "                self.processed_data[self.value_column] = self.processed_data[self.value_column].diff()\n",
        "                self.processed_data.dropna(inplace=True)\n",
        "\n",
        "        return self.processed_data\n",
        "\n",
        "    def plot_acf_pacf(self, lags=10):\n",
        "        '''\n",
        "        plot the acf and pacf\n",
        "        '''\n",
        "        plt.figure(figsize=(12, 10))\n",
        "\n",
        "        plt.subplot(221)\n",
        "        self.processed_data[self.value_column].plot(kind='line')\n",
        "        plt.title('Original Time Series')\n",
        "\n",
        "        plt.subplot(222)\n",
        "        self.processed_data[self.value_column].plot(kind='hist')\n",
        "        plt.title('Original Time Series Histogram')\n",
        "\n",
        "        self.make_stationarity()\n",
        "\n",
        "        plt.subplot(223)\n",
        "        self.processed_data[self.value_column].plot(kind='line')\n",
        "        plt.title('Stationary Time Series')\n",
        "\n",
        "        plt.subplot(224)\n",
        "        self.processed_data[self.value_column].plot(kind='hist')\n",
        "        plt.title('Stationary Time Series Histogram')\n",
        "\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "\n",
        "        plt.figure(figsize=(12, 6))\n",
        "        plt.subplot(121)\n",
        "        plot_acf(self.processed_data[self.value_column], lags=lags, ax=plt.gca(), alpha=0.05)\n",
        "        plt.title('Autocorrelation Function (ACF)')\n",
        "\n",
        "        plt.subplot(122)\n",
        "        plot_pacf(self.processed_data[self.value_column], lags=lags, ax=plt.gca(), alpha=0.05)\n",
        "        plt.title('Partial Autocorrelation Function (PACF)')\n",
        "\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "\n",
        "    def check_normality(self, sample_size_threshold=50):\n",
        "        '''\n",
        "        check the normality\n",
        "        '''\n",
        "        series = self.processed_data[self.value_column]\n",
        "        n = len(series)\n",
        "\n",
        "        if n <= sample_size_threshold:\n",
        "            print('===========================================')\n",
        "            print('Using Shapiro-Wilk test')\n",
        "            print('===========================================')\n",
        "            statistic, p_value = shapiro(series)\n",
        "        else:\n",
        "            print('===========================================')\n",
        "            print('Using Kolmogorov-Smirnov test')\n",
        "            print('===========================================')\n",
        "            statistic, p_value = kstest(series, 'norm', args=(series.mean(), series.std()))\n",
        "\n",
        "        print('====================================================')\n",
        "        print('Statistic: %f' % statistic)\n",
        "        print('p-value: %f' % p_value)\n",
        "        print('====================================================')\n",
        "\n",
        "        if p_value > 0.05:\n",
        "            print('The data is normally distributed')\n",
        "        else:\n",
        "            print('The data is not normally distributed')\n",
        "\n",
        "        return statistic, p_value\n",
        "\n",
        "    def check_white_noise(self, lags=20):\n",
        "        '''\n",
        "        check the white noise\n",
        "        '''\n",
        "        lb_test = acorr_ljungbox(self.processed_data[self.value_column], lags=[lags], return_df=True)\n",
        "        print('====================================================')\n",
        "        print(lb_test)\n",
        "        print('====================================================')\n",
        "        if lb_test['lb_pvalue'].iloc[0] > 0.05:\n",
        "            print('The time series is white noise')\n",
        "        else:\n",
        "            print('The time series is not white noise')\n",
        "\n",
        "    def calculate_statistics(self):\n",
        "        '''\n",
        "        calculate the mean, standard deviation, and ACF\n",
        "        '''\n",
        "        series = self.processed_data[self.value_column]\n",
        "\n",
        "        return {\n",
        "            'mean': series.mean(),\n",
        "            'std': series.std(),\n",
        "            'acf': acf(series)[1:]\n",
        "        }\n",
        "\n",
        "    def run_analysis(self, fill_method=None, differencing_order=1, lags=20):\n",
        "        '''\n",
        "        run the complete analysis\n",
        "        '''\n",
        "        self.is_full_range_time_series()\n",
        "        self.drop_minute_value()\n",
        "        self.check_missing_values(fill_method)\n",
        "        self.make_stationarity(differencing_order)\n",
        "        self.plot_acf_pacf(lags)\n",
        "        self.check_white_noise(lags)\n",
        "        self.check_normality()\n",
        "        stats = self.calculate_statistics()\n",
        "\n",
        "        print('====================================================')\n",
        "        print(f\"Mean: {stats['mean']}\")\n",
        "        print(f\"Standard Deviation: {stats['std']}\")\n",
        "        print('ACF:')\n",
        "        print(stats['acf'])\n",
        "        print('====================================================')\n"
      ],
      "metadata": {
        "id": "bPdVt9HYes_q"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "yUVNg5OLfUsy"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}