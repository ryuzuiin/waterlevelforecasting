{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNrmhyHOjN4l0IHDjQJho7J",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ryuzuiin/waterlevelforecasting/blob/main/%E6%99%82%E7%B3%BB%E5%88%97%E5%88%86%E6%9E%90.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import statsmodels.api as sm\n",
        "from statsmodels.tsa.stattools import adfuller, kpss, acf, pacf\n",
        "from statsmodels.tsa.arima_model import ARIMA\n",
        "\n",
        "from matplotlib.pylab import rcParams\n",
        "rcParams['figure.figsize'] = 15, 6\n",
        "from statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n",
        "\n",
        "from statsmodels.stats.diagnostic import acorr_ljungbox\n",
        "from scipy.stats import shapiro"
      ],
      "metadata": {
        "id": "1cXPNChMPuFC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 1. 定常性検定\n",
        "\n",
        "\n",
        "\n",
        "*   ADF test\n",
        "*   KPSS test(trend stationary)\n",
        "\n"
      ],
      "metadata": {
        "id": "3IV36LwcMq9w"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UQ76mzq2MjEB"
      },
      "outputs": [],
      "source": [
        "def is_stationary(data, significance_level=0.05):\n",
        "  '''\n",
        "  １．定常性検定\n",
        "  input : time seires, significance level\n",
        "  output : bool value\n",
        "  '''\n",
        "  result = adfuller(ts)\n",
        "  print('ADF Statistic: %f' % result[0])\n",
        "  print('p-value: %f' % result[1])\n",
        "  return result[1] <= significance_level\n",
        "\n",
        "def is_trend_stationary(ts, significance_level=0.05):\n",
        "  '''\n",
        "  １．定常性検定for trend\n",
        "  input : time seires\n",
        "  output : booleann value\n",
        "  '''\n",
        "  result = kpss(ts, regression='ct')\n",
        "  print('KPSS Statistic: %f' % result[0])\n",
        "  print('p-value: %f' % result[1])\n",
        "  return result[1] > significance_level\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.1 make stationary"
      ],
      "metadata": {
        "id": "HhhPW5rehFv3"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "OJYStBE3P8fG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 2. White noise 検定(残差分析も同じ）\n",
        "\n",
        "If a time series is white noise, it is a sequence of random numbers and cannot be predicted. If the series of forecast errors are not white noise, it suggests improvements could be made to the predictive model.\n",
        "*   Is the mean/level non-zero?\n",
        "*   Does the mean/level change over time?\n",
        "*   Does the variance change over time?\n",
        "*   Do values correlate with lag values?\n"
      ],
      "metadata": {
        "id": "7dY8yFbNVktx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def is_white_noise(ts):\n",
        "  '''\n",
        "  ２．WNS検定\n",
        "  input : time seires\n",
        "  output : dict of result\n",
        "  '''\n",
        "  print(ts.describe())\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "2heBzlv4Vd8m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "9AyWE3VANNks"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "eTUV4uMWhT3M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class TimeSeriesAnalyzer:\n",
        "  def __init__(self, data, date_column, value_column, freq='10T'):\n",
        "    self.data = data\n",
        "    self.date_column = date_column\n",
        "    self.value_column = value_column\n",
        "    self.freq = freq\n",
        "    self.processed_data = None\n",
        "\n",
        "  def is_datetime_column(self):\n",
        "    '''\n",
        "    detect the datetime column\n",
        "\n",
        "    '''\n",
        "    if self.date_column in self.data.columns:\n",
        "      return pd.api.types.is_datetime64_any_dtype(self.data[self.date_column])\n",
        "    else:\n",
        "      raise ValueError(f' column {self.date_column} is not found in data')\n",
        "\n",
        "  def make_datetime(self):\n",
        "    '''\n",
        "    if  not datetime type,  convert to datetime type.\n",
        "    input: data[date_column]\n",
        "    output: data[date_column\n",
        "    '''\n",
        "    if not self.is_datetime_column():\n",
        "      self.data[self.date_column] = pd.to_datetime(self.data[self.date_column])\n",
        "      return self.data[self.date_column]\n",
        "    else:\n",
        "      return self.data[self.date_column]\n",
        "\n",
        "  def is_time_ordered(self):\n",
        "    '''\n",
        "    detect the time order\n",
        "    input: data[date_column]\n",
        "    output: bool\n",
        "    '''\n",
        "    if self.is_datetime_column():\n",
        "      return self.data[self.date_column].is_monotonic_increasing\n",
        "    else:\n",
        "      return self.make_datetime().is_monotonic_increasing\n",
        "\n",
        "  def set_date_index(self):\n",
        "    if self.is_time_ordered():\n",
        "      self.data.set_index(self.date_column, inplace=True)\n",
        "      return self.data\n",
        "    else:\n",
        "      self.data.sort_values(by=self.date_column, inplace=True)\n",
        "      self.data.set_index(self.date_column, inplace=True)\n",
        "      return self.data\n",
        "\n",
        "  #hundling missing value\n",
        "  def check_missing_values(self, fill_method=None):\n",
        "    '''\n",
        "    detect the missing value and handle them\n",
        "\n",
        "    input:fill_method\n",
        "    output:boolean value\n",
        "    '''\n",
        "    missing_values = self.data[self.value_column].isnull().sum()\n",
        "\n",
        "    if missing_values > 0:\n",
        "      print(f'{missing_values} missing data found')\n",
        "\n",
        "      if fill_method == 'ffill':\n",
        "        self.data[self.value_column].fillna(method='ffill', inplace=True)\n",
        "      elif fill_method == 'bfill':\n",
        "        self.data[self.value_column].fillna(method='bill', inplace=True)\n",
        "      elif fill_method =='mean':\n",
        "        self.fill_with_mean_of_neighbor()\n",
        "      elif fill_method=='drop':\n",
        "        self.data.dropna(subset=[self.value_column], inplace=True)\n",
        "      elif fill_method =='linear':\n",
        "        self.data[self.value_column].interpolate(method='linear', inplace=True)\n",
        "      elif fill_method == 'time':\n",
        "        self.data[self.value_column].interpolate(method='time', inplace=True)\n",
        "\n",
        "      return True\n",
        "    else:\n",
        "      print('No missing data found')\n",
        "      return False\n",
        "\n",
        "  def fill_with_mean_of_neighbor(self):\n",
        "    '''\n",
        "    fill the missing value with mean of neighbor\n",
        "    '''\n",
        "    for i in range(1, len(self.data) - 1):\n",
        "      if pd.isnull(self.data.loc[i,self.value_column]):\n",
        "        prev_value = self.data.loc[i-1, self.value_column]\n",
        "        next_value =self.data.loc[i+1, self.value_column]\n",
        "        if pd.notnull(prev_value) and pd.notnull(next_value):\n",
        "          self.data.loc[i,self.value_column] = (prev_value + next_value)/2\n",
        "\n",
        "  #constructing a full range time series\n",
        "  def is_full_range_time_series(self):\n",
        "    '''\n",
        "    check the full range time series and construct a full range time series\n",
        "    '''\n",
        "    if not isinstance(self.data.index, pd.DatetimeIndex):\n",
        "      self.set_date_index()\n",
        "\n",
        "    full_range = pd.date_range(start=self.data.index.min(), end=self.data.index.max(), freq=self.freq)\n",
        "\n",
        "    is_full_range = self.data.index.equals(full_range)\n",
        "\n",
        "    if is_full_range:\n",
        "      print('The time series is a full range time series')\n",
        "      self.processed_data = self.data.copy()\n",
        "    else:\n",
        "      print('The time series is not a full range time series')\n",
        "      self.processed_data = self.data.reindex(full_range)\n",
        "      self.processed_data.check_missing_values(fill_method)\n",
        "      self.processed_data.sort_index(inplace=True)\n",
        "\n",
        "    return self.processed_data\n",
        "\n",
        "  def drop_minute_value(self, minutes_to_drop=[15, 45]):\n",
        "    '''\n",
        "    drop the unnessary minute value\n",
        "    '''\n",
        "    if not isinstance(self.data.index, pd.DatetimeIndex):\n",
        "      self.set_date_index()\n",
        "\n",
        "    self.data = self.data[~self.data.index.minute.isin(minutes_to_drop)]\n",
        "    return self.data\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "VrcpneguhTzx"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}